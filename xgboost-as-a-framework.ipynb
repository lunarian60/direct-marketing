{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba974f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing abalone.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile abalone.py\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sagemaker_containers import entry_point\n",
    "from sagemaker_xgboost_container import distributed\n",
    "from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "\n",
    "\n",
    "def _xgb_train(params, dtrain, evals, num_boost_round, model_dir, is_master):\n",
    "    \"\"\"Run xgb train on arguments given with rabit initialized.\n",
    "    This is our rabit execution function.\n",
    "    :param args_dict: Argument dictionary used to run xgb.train().\n",
    "    :param is_master: True if current node is master host in distributed training,\n",
    "                        or is running single node training job.\n",
    "                        Note that rabit_run will include this argument.\n",
    "    \"\"\"\n",
    "    booster = xgb.train(params=params, dtrain=dtrain, evals=evals, num_boost_round=num_boost_round)\n",
    "\n",
    "    if is_master:\n",
    "        model_location = model_dir + \"/xgboost-model\"\n",
    "        pkl.dump(booster, open(model_location, \"wb\"))\n",
    "        logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument(\n",
    "        \"--max_depth\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\"--eta\", type=float)\n",
    "    parser.add_argument(\"--gamma\", type=int)\n",
    "    parser.add_argument(\"--min_child_weight\", type=int)\n",
    "    parser.add_argument(\"--subsample\", type=float)\n",
    "    parser.add_argument(\"--verbosity\", type=int)\n",
    "    parser.add_argument(\"--objective\", type=str)\n",
    "    parser.add_argument(\"--num_round\", type=int)\n",
    "    parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--sm_hosts\", type=str, default=os.environ.get(\"SM_HOSTS\"))\n",
    "    parser.add_argument(\"--sm_current_host\", type=str, default=os.environ.get(\"SM_CURRENT_HOST\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(args.sm_hosts)\n",
    "    sm_current_host = args.sm_current_host\n",
    "\n",
    "    dtrain = get_dmatrix(args.train, \"libsvm\")\n",
    "    dval = get_dmatrix(args.validation, \"libsvm\")\n",
    "    watchlist = (\n",
    "        [(dtrain, \"train\"), (dval, \"validation\")] if dval is not None else [(dtrain, \"train\")]\n",
    "    )\n",
    "\n",
    "    train_hp = {\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"eta\": args.eta,\n",
    "        \"gamma\": args.gamma,\n",
    "        \"min_child_weight\": args.min_child_weight,\n",
    "        \"subsample\": args.subsample,\n",
    "        \"verbosity\": args.verbosity,\n",
    "        \"objective\": args.objective,\n",
    "        \"tree_method\": args.tree_method,\n",
    "        \"predictor\": args.predictor,\n",
    "    }\n",
    "\n",
    "    xgb_train_args = dict(\n",
    "        params=train_hp,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=args.num_round,\n",
    "        model_dir=args.model_dir,\n",
    "    )\n",
    "\n",
    "    if len(sm_hosts) > 1:\n",
    "        # Wait until all hosts are able to find each other\n",
    "        entry_point._wait_hostname_resolution()\n",
    "\n",
    "        # Execute training function after initializing rabit.\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True,\n",
    "        )\n",
    "    else:\n",
    "        # If single node training, call training method directly.\n",
    "        if dtrain:\n",
    "            xgb_train_args[\"is_master\"] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"Training channel must have data to train model.\")\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))\n",
    "    return booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55aa1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.xgboost import XGBoost, XGBoostModel\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6bd2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        \"max_depth\": \"5\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "        \"subsample\": \"0.7\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"num_round\": \"50\",\n",
    "        \"verbosity\": \"2\",\n",
    "    }\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = 'yudong-data'\n",
    "prefix = 'DEMO-xgboost-as-a-framework'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb-framework')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8669764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 203 ms, sys: 15.6 ms, total: 218 ms\n",
      "Wall time: 1.97 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://yudong-data/DEMO-xgboost-as-a-framework/train/abalone'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s3 = boto3.client(\"s3\")\n",
    "# Load the dataset\n",
    "FILE_DATA = \"abalone\"\n",
    "s3.download_file(\n",
    "    \"sagemaker-sample-files\", f\"datasets/tabular/uci_abalone/abalone.libsvm\", FILE_DATA\n",
    ")\n",
    "sagemaker.Session().upload_data(FILE_DATA, bucket=bucket, key_prefix=prefix + \"/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5196af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBoost(entry_point = \"abalone.py\", \n",
    "                    framework_version='1.2-2',\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    instance_count=1,\n",
    "                    instance_type='local',\n",
    "                    output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f517fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = TrainingInput(\"s3://yudong-data/DEMO-xgboost-as-a-framework/train/abalone\", content_type=\"text/libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80702ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.inputs.TrainingInput at 0x7ff41db26320>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903ba1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating cpjv7h6pwe-algo-1-l8fao ... \n",
      "Creating cpjv7h6pwe-algo-1-l8fao ... done\n",
      "Attaching to cpjv7h6pwe-algo-1-l8fao\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21 15:29:45.249 48645729713d:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Invoking user training script.\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Module abalone does not provide a setup.py. \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Generating setup.py\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Generating setup.cfg\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Generating MANIFEST.in\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:45:INFO] Installing module with the following command:\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m    pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Building wheels for collected packages: abalone\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m   Building wheel for abalone (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \u001b[?25h  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=5839 sha256=10ff0f0b391ef63db96119f3850af11037fea217730d765aea5ff811f2ceb428\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-r__e0fdq/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Successfully built abalone\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Installing collected packages: abalone\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Successfully installed abalone-1.0.0\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:46:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2021-07-21:15:29:46:INFO] Invoking user script\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Training Env:\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     },\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"current_host\": \"algo-1-l8fao\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"algo-1-l8fao\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     ],\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"max_depth\": \"5\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"eta\": \"0.2\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"gamma\": \"4\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"min_child_weight\": \"6\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"subsample\": \"0.7\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"verbosity\": \"1\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"objective\": \"reg:linear\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"num_round\": \"50\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     },\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"train\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m             \"ContentType\": \"text/libsvm\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         },\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"validation\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m             \"ContentType\": \"text/libsvm\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         }\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     },\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2021-07-21-15-29-42-361\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"master_hostname\": \"algo-1-l8fao\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"module_dir\": \"s3://yudong-data/sagemaker-xgboost-2021-07-21-15-29-42-361/source/sourcedir.tar.gz\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"module_name\": \"abalone\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"current_host\": \"algo-1-l8fao\",\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m             \"algo-1-l8fao\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m         ]\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     },\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m     \"user_entry_point\": \"abalone.py\"\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m }\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Environment variables:\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HOSTS=[\"algo-1-l8fao\"]\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HPS={\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\",\"verbosity\":\"1\"}\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_USER_ENTRY_POINT=abalone.py\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-l8fao\",\"hosts\":[\"algo-1-l8fao\"]}\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/libsvm\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/libsvm\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_CURRENT_HOST=algo-1-l8fao\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_MODULE_NAME=abalone\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_MODULE_DIR=s3://yudong-data/sagemaker-xgboost-2021-07-21-15-29-42-361/source/sourcedir.tar.gz\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-l8fao\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-l8fao\"],\"hyperparameters\":{\"eta\":\"0.2\",\"gamma\":\"4\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"num_round\":\"50\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\",\"verbosity\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/libsvm\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/libsvm\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2021-07-21-15-29-42-361\",\"log_level\":20,\"master_hostname\":\"algo-1-l8fao\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://yudong-data/sagemaker-xgboost-2021-07-21-15-29-42-361/source/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-l8fao\",\"hosts\":[\"algo-1-l8fao\"]},\"user_entry_point\":\"abalone.py\"}\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:linear\",\"--subsample\",\"0.7\",\"--verbosity\",\"1\"]\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_MAX_DEPTH=5\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_ETA=0.2\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_GAMMA=4\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_MIN_CHILD_WEIGHT=6\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_SUBSAMPLE=0.7\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_VERBOSITY=1\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_OBJECTIVE=reg:linear\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m SM_HP_NUM_ROUND=50\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m /miniconda3/bin/python3 -m abalone --eta 0.2 --gamma 4 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:linear --subsample 0.7 --verbosity 1\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m \n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [15:29:47] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [0]\ttrain-rmse:8.09086\tvalidation-rmse:8.09086\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [1]\ttrain-rmse:6.61128\tvalidation-rmse:6.61128\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [2]\ttrain-rmse:5.44558\tvalidation-rmse:5.44558\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [3]\ttrain-rmse:4.54894\tvalidation-rmse:4.54894\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [4]\ttrain-rmse:3.85380\tvalidation-rmse:3.85380\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [5]\ttrain-rmse:3.32450\tvalidation-rmse:3.32450\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [6]\ttrain-rmse:2.92907\tvalidation-rmse:2.92907\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [7]\ttrain-rmse:2.64925\tvalidation-rmse:2.64925\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [8]\ttrain-rmse:2.43828\tvalidation-rmse:2.43828\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [9]\ttrain-rmse:2.28504\tvalidation-rmse:2.28504\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [10]\ttrain-rmse:2.17757\tvalidation-rmse:2.17757\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [11]\ttrain-rmse:2.10257\tvalidation-rmse:2.10257\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [12]\ttrain-rmse:2.04681\tvalidation-rmse:2.04681\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [13]\ttrain-rmse:2.00737\tvalidation-rmse:2.00737\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [14]\ttrain-rmse:1.97778\tvalidation-rmse:1.97778\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [15]\ttrain-rmse:1.95060\tvalidation-rmse:1.95060\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [16]\ttrain-rmse:1.93036\tvalidation-rmse:1.93036\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [17]\ttrain-rmse:1.91997\tvalidation-rmse:1.91997\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [18]\ttrain-rmse:1.90255\tvalidation-rmse:1.90255\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [19]\ttrain-rmse:1.88461\tvalidation-rmse:1.88461\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [20]\ttrain-rmse:1.87660\tvalidation-rmse:1.87660\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [21]\ttrain-rmse:1.86282\tvalidation-rmse:1.86282\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [22]\ttrain-rmse:1.85499\tvalidation-rmse:1.85499\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [23]\ttrain-rmse:1.84877\tvalidation-rmse:1.84877\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [24]\ttrain-rmse:1.84014\tvalidation-rmse:1.84014\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [25]\ttrain-rmse:1.83703\tvalidation-rmse:1.83703\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [26]\ttrain-rmse:1.82825\tvalidation-rmse:1.82825\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [27]\ttrain-rmse:1.82615\tvalidation-rmse:1.82615\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [28]\ttrain-rmse:1.81786\tvalidation-rmse:1.81786\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [29]\ttrain-rmse:1.81118\tvalidation-rmse:1.81118\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [30]\ttrain-rmse:1.80298\tvalidation-rmse:1.80298\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [31]\ttrain-rmse:1.79703\tvalidation-rmse:1.79703\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [32]\ttrain-rmse:1.78973\tvalidation-rmse:1.78973\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [33]\ttrain-rmse:1.78096\tvalidation-rmse:1.78096\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [34]\ttrain-rmse:1.77939\tvalidation-rmse:1.77939\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [35]\ttrain-rmse:1.77712\tvalidation-rmse:1.77712\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [36]\ttrain-rmse:1.77266\tvalidation-rmse:1.77266\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [37]\ttrain-rmse:1.76878\tvalidation-rmse:1.76878\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [38]\ttrain-rmse:1.76343\tvalidation-rmse:1.76343\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [39]\ttrain-rmse:1.75774\tvalidation-rmse:1.75774\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [40]\ttrain-rmse:1.75110\tvalidation-rmse:1.75110\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [41]\ttrain-rmse:1.74668\tvalidation-rmse:1.74668\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [42]\ttrain-rmse:1.74404\tvalidation-rmse:1.74404\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [43]\ttrain-rmse:1.74232\tvalidation-rmse:1.74232\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [44]\ttrain-rmse:1.73694\tvalidation-rmse:1.73694\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [45]\ttrain-rmse:1.73464\tvalidation-rmse:1.73464\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [46]\ttrain-rmse:1.72677\tvalidation-rmse:1.72677\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [47]\ttrain-rmse:1.72361\tvalidation-rmse:1.72361\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [48]\ttrain-rmse:1.71716\tvalidation-rmse:1.71716\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [49]\ttrain-rmse:1.70623\tvalidation-rmse:1.70623\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao |\u001b[0m [15:29:47] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\u001b[36mcpjv7h6pwe-algo-1-l8fao exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\": train_input, \"validation\": train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "160957d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ff80a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://yudong-data/DEMO-xgboost-as-a-framework/abalone-xgb-framework/output/sagemaker-xgboost-2021-07-21-15-29-42-361/model.tar.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64863861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference-abalone.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference-abalone.py\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import sagemaker_xgboost_container.encoder as xgb_encoders\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))\n",
    "    return booster\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    The SageMaker XGBoost model server receives the request data body and the content type,\n",
    "    and invokes the `input_fn`.\n",
    "    Return a DMatrix (an object that can be passed to predict_fn).\n",
    "    \"\"\"\n",
    "    if request_content_type == \"text/libsvm\":\n",
    "        return xgb_encoders.libsvm_to_dmatrix(request_body)\n",
    "    else:\n",
    "        raise ValueError(\"Content type {} is not supported.\".format(request_content_type))\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    SageMaker XGBoost model server invokes `predict_fn` on the return value of `input_fn`.\n",
    "    Return a two-dimensional NumPy array where the first columns are predictions\n",
    "    and the remaining columns are the feature contributions (SHAP values) for that prediction.\n",
    "    \"\"\"\n",
    "    prediction = model.predict(input_data)\n",
    "    feature_contribs = model.predict(input_data, pred_contribs=True, validate_features=False)\n",
    "    output = np.hstack((prediction[:, np.newaxis], feature_contribs))\n",
    "    return output\n",
    "\n",
    "\n",
    "def output_fn(predictions, content_type):\n",
    "    \"\"\"\n",
    "    After invoking predict_fn, the model server invokes `output_fn`.\n",
    "    \"\"\"\n",
    "    if content_type == \"text/csv\":\n",
    "        return \",\".join(str(x) for x in predictions[0])\n",
    "    else:\n",
    "        raise ValueError(\"Content type {} is not supported.\".format(content_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b13d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_inference_model = XGBoostModel(\n",
    "        model_data=model_data,\n",
    "        role=sagemaker.get_execution_role(),\n",
    "        entry_point=\"inference-abalone.py\",\n",
    "        framework_version=\"1.2-1\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27360b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 51968qvjvf-algo-1-deh8j\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] nginx config: \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m worker_processes auto;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m daemon off;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m events {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m http {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   server {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     location / {\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m }\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] Module inference-abalone does not provide a setup.py. \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Generating setup.py\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] Generating setup.cfg\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] Generating MANIFEST.in\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:45:INFO] Installing module with the following command:\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Building wheels for collected packages: inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   Building wheel for inference-abalone (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \u001b[?25h  Created wheel for inference-abalone: filename=inference_abalone-1.0.0-py2.py3-none-any.whl size=4353 sha256=2caf0ddb432bc624477e06516283eb726e6f1b4ba9b869b6d43c396087ec7fe9\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-awr_rezr/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Successfully built inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Installing collected packages: inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Successfully installed inference-abalone-1.0.0\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [49] [INFO] Starting gunicorn 19.10.0\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [49] [INFO] Listening at: unix:/tmp/gunicorn.sock (49)\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [49] [INFO] Using worker: gevent\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [52] [INFO] Booting worker with pid: 52\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [53] [INFO] Booting worker with pid: 53\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:46 +0000] [61] [INFO] Booting worker with pid: 61\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:47 +0000] [62] [INFO] Booting worker with pid: 62\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:47 +0000] [63] [INFO] Booting worker with pid: 63\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:47 +0000] [64] [INFO] Booting worker with pid: 64\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:47 +0000] [72] [INFO] Booting worker with pid: 72\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21 15:40:47 +0000] [73] [INFO] Booting worker with pid: 73\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:49:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [2021-07-21:15:40:49:INFO] Installing module with the following command:\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Building wheels for collected packages: inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   Building wheel for inference-abalone (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m \u001b[?25h  Created wheel for inference-abalone: filename=inference_abalone-1.0.0-py2.py3-none-any.whl size=4353 sha256=c6ff55caf6d762f194e056fbbcbf5f557ba978d9cd26743668d3d628b0ef9c70\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-782ikwkm/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Successfully built inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Installing collected packages: inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m   Attempting uninstall: inference-abalone\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     Found existing installation: inference-abalone 1.0.0\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m     Uninstalling inference-abalone-1.0.0:\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m       Successfully uninstalled inference-abalone-1.0.0\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m Successfully installed inference-abalone-1.0.0\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m [15:40:50] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "!\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m 172.18.0.1 - - [21/Jul/2021:15:40:50 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.5\"\n"
     ]
    }
   ],
   "source": [
    "predictor = xgb_inference_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"local\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac76db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference_on_local_endpoint(predictor, libsvm_str):\n",
    "    label, *features = libsvm_str.strip().split()\n",
    "    predictions = predictor.predict(\" \".join([\"-99\"] + features))  # use dummy label -99\n",
    "    print(\"Prediction: {}\".format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fd72263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [['6.8532515', '0.0', '-0.3545924', '-0.12613766', '-0.36350462', '-0.37387854', '-0.83996755', '1.5954899', '0.38270319', '-2.9971762', '9.930313']]\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m 172.18.0.1 - - [21/Jul/2021:15:41:11 +0000] \"POST /invocations HTTP/1.1\" 200 113 \"-\" \"python-urllib3/1.26.5\"\n",
      "Prediction: [['14.508704', '0.0', '-0.0045526065', '-0.07738679', '0.023501989', '0.35198748', '0.9640153', '0.92003435', '0.040878277', '2.3599126', '9.930313']]\n",
      "\u001b[36m51968qvjvf-algo-1-deh8j |\u001b[0m 172.18.0.1 - - [21/Jul/2021:15:41:11 +0000] \"POST /invocations HTTP/1.1\" 200 114 \"-\" \"python-urllib3/1.26.5\"\n"
     ]
    }
   ],
   "source": [
    "a_young_abalone = \"6 1:3 2:0.37 3:0.29 4:0.095 5:0.249 6:0.1045 7:0.058 8:0.067\"\n",
    "do_inference_on_local_endpoint(predictor, a_young_abalone)\n",
    "\n",
    "an_old_abalone = \"15 1:1 2:0.655 3:0.53 4:0.175 5:1.2635 6:0.486 7:0.2635 8:0.415\"\n",
    "do_inference_on_local_endpoint(predictor, an_old_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02521743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
